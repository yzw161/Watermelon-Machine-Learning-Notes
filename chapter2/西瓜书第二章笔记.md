# 第二章 模型评估与选择
## 2.1 经验误差与过拟合
过拟合vs欠拟合

![image](https://github.com/user-attachments/assets/eac9e47e-e89d-4b1c-a19b-aa65d2975002)

![image](https://github.com/user-attachments/assets/5c015e98-8482-478b-8590-edfd2dc959ab)

## 2.2 评估方法
首先要区分测试机与训练集，有三种方法
### 方法一 留出法

直接区分为两个互斥的集合，需要注意：

- 训练/测试集的划分要尽可能保持数据分布的一致性，可以采用分层采样
- 即便在给定训练/测试集的样本比例后，仍存在多种划分方式对初始数据集进行分割。因此，单次使用留出法得到的估计结果往往不够稳定可靠,在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作留出法的评估结果
- 常见做法是将大约2/3-4/5的样本用于训练，剩余样本用于测试

### 方法二 交叉验证法
示意图如下：

![image](https://github.com/user-attachments/assets/74a1384f-5249-4208-a927-757eac568698)

需要注意的是：也需要进行多次取平均值。

当如果一共有m个样本，k=m时为**留一法**。好处是：
- 几乎用到了所有数据，评估结果更可靠。
- 特别适合小数据集，避免了数据浪费。（但是对于大数据集来说计算开销过大）
- 无随机性，结果稳定。

适用于数据量较小（比如几十到几百个样本）或需要高精度的模型评估。

### 方法三 自助法

自助法是一种从数据集中随机抽取样本的方法，用来创建训练集和测试集。它的核心思想是通过有放回地随机抽样来生成多个不同的数据集，从而评估模型的性能。
具体步骤
有放回地随机抽样：

- 假设你有一个包含N个样本的数据集。从这 N个样本中随机抽取一个样本，记录后放回数据集。
- 重复这个过程 N次，得到一个新的数据集（训练集）。
- 由于是有放回抽样，有些样本可能会被抽到多次，而有些样本可能一次都没被抽到。并且把从来没抽到的设置为测试集。

说明：从来没被抽中的概率如下：

![image](https://github.com/user-attachments/assets/4bb00c57-06a6-49c4-aa58-bc9b1a1ab80d)

通过该方法我们仍有数据总量约1/3的、没在训练集中出现的样本用于测试。这样的测试结果，亦称 “包外估计”。

#### 举例
- 假设你有 5 个苹果，编号为 1、2、3、4、5。
- 你随机抽取 5 次（每次抽完放回），可能得到这样的结果：1、3、3、5、2。
- 训练集：1、2、3、3、5（注意，3 被抽到了两次）。
- 测试集：4（因为 4 没有被抽到）。

自助法的特点：
- 当数据量很少时，自助法可以生成多个不同的训练集，充分利用数据
- 自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差

### 调参与最终模型
调参：确定范围和变化步长，在计算开销和性能中折中。
区分训练集&测试集vs验证集

## 2.3 性能度量

对于回归任务一般使用MSE

![image](https://github.com/user-attachments/assets/6426c751-377d-426d-bb99-87f33882b1b3)

对于分类任务一般使用如下方法：

### 2.3.1 错误率与精度
错误率是分类错误的样本数占样本总数的比例,精度则是分类正确的样本数占样本总数的比例。

### 2.3.2 查准率、查全率与F1
## 表 2.1 分类结果混淆矩阵

| 真实情况 | 预测结果       |                |
|----------|----------------|----------------|
|          | 正例           | 反例           |
| 正例     | TP（真正例）    | FN（假反例）    |
| 反例     | FP（假正例）    | TN（真反例）    |

查准率P与查全率R分别定义为

$$
P = \frac{TP}{TP + FP}
$$
$$
R = \frac{TP}{TP + FN}
$$

查准率与查全率一般来说不可兼得，通过计算可以绘制P-R图

![image](https://github.com/user-attachments/assets/465a9116-2aa8-43cb-8778-52e46147882e)

- 若一个学习器的P -R 曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者，例如A优于C
- 对于并非完全包住的情况，可以考虑“平衡点”（BEP），它是查准率=查全率时的取值，例如A优于B
- 由于BEP过于简单，可以使用P和R的调和平均值进行度量，如下图所示。对于beta值，大于1时查全率影响更大，小于1时查准率影响更大，取决于系统具体更看重哪个。

![image](https://github.com/user-attachments/assets/09fa7cfc-e836-4806-a5bd-16ce42ef9066)

- 对于多个二分类情况，可以采用如下的指标

![image](https://github.com/user-attachments/assets/885b5435-424f-4ed4-889b-73b15552c4a9)

- 或者计算完TP、FP、TN、FN平均值后计算对应的micro值

### 2.3.3 ROC和AUC
根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横、纵坐标作图，就得到了ROC曲线，曲线的纵轴是TPR, 横轴是FPR，计算如下：

![image](https://github.com/user-attachments/assets/b234810e-8a6d-46c7-8c7f-63dd3720a9c9)

![image](https://github.com/user-attachments/assets/1a144a88-0b9f-463b-8ab9-5fb3bcc8209e)

如图所示（0，1）为理想模型，而对角线为随机模型，如果A模型ROC完全被B模型包住，则B优于A；当出现交叉时，则比较ROC包住的面积，也就是AUC的大小。

### 2.3.4 代价敏感错误率与代价曲线
为权衡不同类型错误所造成的不同损失，可为错误赋予非均等代价.本节的概念类似于假设检验中的第一类错误与第二类错误，统计中往往选择控制第一类错误的大小，但是现实中需要基于实际问题来取舍。
具体计算参考如下公式：

![image](https://github.com/user-attachments/assets/20ef9ca0-5bc3-4b1b-8dbc-f840b7229658)

其绘制曲线如下：

![image](https://github.com/user-attachments/assets/f7089eb2-a9cc-4510-8713-6d92ddf91813)

## 2.4 比较检验
### 2.4.1 假设检验
本部分的计算方法与统计学中类似，不再赘述，具体如下示意，即给定错误率和个数，其服从二项分布，则可以对错误率进行假设检验。并且由于前述采样的问题，我们需要多次计算平均值和方差，进行双边t检验。

![image](https://github.com/user-attachments/assets/c789b44f-aab5-425c-b0de-a15410a761f9)

### 2.4.2 交叉验证t检验
由于测试错误率不独立，不能使用经典的配对t检验，故进行修正，如下所示：

![image](https://github.com/user-attachments/assets/bb2f8382-4ed8-4194-8650-b61658e470e5)

其本质思想仍是配对t检验。

### 2.4.3 McNemar 检验
**相当于2*2列联表检验**

![image](https://github.com/user-attachments/assets/7e237f64-60d2-4c38-8788-4a0af49f79c1)

### 2.4.4 Friedman检验与Nemenyi后续检验
#### Friedman检验
##### 通俗解释
Friedman检验是一种统计方法，用来比较多个算法在多个数据集上的表现是否有显著差异。它的核心思想是：对每个数据集中的算法进行排名，然后比较这些排名的分布是否一致。

##### 举个例子：
- 假设你有 3 种算法（A、B、C），在 5 个数据集上测试它们的性能。
- 在每个数据集上，你根据算法的表现给它们排名（比如第 1 名、第 2 名、第 3 名）。
- 然后，Friedman检验会分析这些排名，看看算法之间的表现是否有显著差异。

##### 适用场景
- 当你需要在多个数据集上比较多个算法时。
- 当你不知道数据的分布是否符合正态分布时（Friedman检验是非参数检验，不依赖于数据分布）。

#### Nemenyi后续检验
##### 通俗解释
Nemenyi后续检验是Friedman检验的补充。如果Friedman检验发现算法之间有显著差异，Nemenyi后续检验可以进一步告诉我们哪些算法之间的差异是显著的。

##### 举个例子：
假设Friedman检验发现算法 A、B、C 的表现有显著差异。Nemenyi后续检验会进一步比较：

- A 和 B 之间是否有显著差异？
- A 和 C 之间是否有显著差异？
- B 和 C 之间是否有显著差异？

##### 关键点
Nemenyi后续检验会计算一个临界值（Critical Difference, CD），如果两个算法的排名差异超过这个临界值，就认为它们之间的差异是显著的。

**其判断方法可以使用下图**

![image](https://github.com/user-attachments/assets/07e6072c-7b3a-416d-b36e-82fa2130a04d)

## 2.5 偏差和方差
**与统计学中推导一致** 公式如下所示：

![image](https://github.com/user-attachments/assets/877d8e87-af94-4af9-8a75-1d933357de8f)


- 偏差（Bias）：偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。
- 方差（Variance）：方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。
- 噪声（Noise）：噪声表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。

偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。给定学习任务，为了取得好的泛化性能，则需使偏差较小（即能够充分拟合数据），并且使方差较小（即使得数据扰动产生的影响小）。一般来说无法同时控制偏差和方差（类似于欠拟合和过拟合），如下图所示：

![image](https://github.com/user-attachments/assets/2323d4fb-8656-454e-aa78-003b2f492d7c)

## 2.6 阅读材料
略















